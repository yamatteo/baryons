{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c09de82-546b-4467-b756-415daf76b39f",
   "metadata": {},
   "source": [
    "## Some tests about the monolithic preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1851d3d-8c6a-45fb-afba-de1e8f3d09e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark matter particles\n",
      "[[ 1.04231418e+01 -6.40194738e+00 -1.61657979e+00  4.72394449e-02]\n",
      " [ 1.13459913e+01 -5.95776642e+00 -1.21491853e+00  4.72394449e-02]\n",
      " [ 9.68148905e+00 -6.86386136e+00 -2.07751967e+00  4.72394449e-02]\n",
      " ...\n",
      " [ 3.41927230e+01  8.02075748e+01 -2.03665752e+01  4.72394449e-02]\n",
      " [-1.10674581e+02  6.11351384e+01 -1.89990026e+00  4.72394449e-02]\n",
      " [-1.61922891e+02  1.69029178e+02 -4.71163264e+00  4.72394449e-02]]\n",
      "Gas particles\n",
      "[[ 1.26990368e+01 -4.45786014e+00 -8.95605058e+00  1.22793103e-02]\n",
      " [ 9.98359735e+00 -2.65588877e+00 -1.13402028e+01  6.87742047e-03]\n",
      " [ 1.86737134e+01 -2.95313115e+00 -1.08345178e+01  1.32554537e-02]\n",
      " ...\n",
      " [ 5.34092582e+01 -8.21173002e+01 -6.43312808e+01  5.61451446e-03]\n",
      " [ 6.79069628e+01 -8.59964206e+01 -6.93208099e+01  8.22646916e-03]\n",
      " [-7.93876567e+01  1.17252220e+02  1.54833089e+01  7.14536477e-03]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from preprocess.monolith import find_ids, find_halo\n",
    "\n",
    "# First utility of the module is the find_ids function. It returns an array of integers.\n",
    "ids = find_ids(\n",
    "    base_path='dataset/TNG100-3/output',\n",
    "    hsmall=0.6774,\n",
    "    snap_num=99,\n",
    "    mass_min=1000000000000.0,\n",
    "    mass_max=5000000000000.0,\n",
    "    n_gas_min=500,\n",
    ")\n",
    "assert isinstance(ids, np.ndarray)\n",
    "assert ids.dtype == np.int64\n",
    "\n",
    "# Secondly, with a loop over all indexes, find_halo build two array of NUM_PARTICLES rows and 4 columns (X, Y, Z, MASS).\n",
    "dm_halo, gas_halo = find_halo(\n",
    "    base_path='dataset/TNG100-3/output',\n",
    "    halo_id=ids[0],\n",
    "    lbox=75000.0,\n",
    "    mdm=472394449.36521995,\n",
    "    snap_num=99\n",
    ")\n",
    "\n",
    "# X, Y and Z can be positive ore negative, because they are relative to the center of mass of the halo. Masses in `dm_halo` are always equal to `mdm / 1e10` and masses of `gas_halo` varies.\n",
    "print(\"Dark matter particles\")\n",
    "print(dm_halo)\n",
    "\n",
    "print(\"Gas particles\")\n",
    "print(gas_halo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a9100f-8137-43aa-817d-90601b8d905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center of dark matter [-1264.38641317  2225.41274029  1976.13679177]\n",
      "Weighted center of dark matter [-59.72891234 105.12726261  93.35160516]\n",
      "Weighted center of gas [-27.61739674 -34.16789986 -48.68320766]\n",
      "Weighted center combined [-87.34630908  70.95936274  44.6683975 ]\n"
     ]
    }
   ],
   "source": [
    "# To test if position are really relative to the center of mass, we can sum all positions od dm_halo, because they have all the same weight.\n",
    "print(\"Center of dark matter\", np.sum(dm_halo[:, :3], axis=0))\n",
    "\n",
    "# Maybe the center of mass is calculated considering dark matter and gas together. Let's weight the positions and sum them.\n",
    "dm_wpos = (dm_halo[:,:3] * dm_halo[:,3].reshape((-1,1)))\n",
    "gas_wpos = (gas_halo[:,:3] * gas_halo[:,3].reshape((-1,1)))\n",
    "\n",
    "print(\"Weighted center of dark matter\", np.sum(dm_wpos, axis=0))\n",
    "print(\"Weighted center of gas\", np.sum(gas_wpos, axis=0))\n",
    "print(\"Weighted center combined\", np.sum(np.vstack([dm_wpos, gas_wpos]), axis=0))\n",
    "\n",
    "# Maybe weights are not the same for dark matter and gas, but no factor can sum the two negative x to 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f064d65c-245f-4bff-a9f5-9d8c46922545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10.42314178   -6.40194738   -1.61657979]\n",
      " [  11.34599131   -5.95776642   -1.21491853]\n",
      " [   9.68148905   -6.86386136   -2.07751967]\n",
      " ...\n",
      " [  34.19272299   80.20757477  -20.36657519]\n",
      " [-110.6745806    61.13513837   -1.89990026]\n",
      " [-161.92289109  169.02917842   -4.71163264]]\n"
     ]
    }
   ],
   "source": [
    "# ... so they are not the positions relative to the center of mass. Nevertheless they are positions.\n",
    "# Doing what voxelize would do we first split the input\n",
    "dm_pos, dm_mass = dm_halo[:, 0:3], dm_halo[:, 3]\n",
    "gas_pos, gas_mass = gas_halo[:, 0:3], gas_halo[:, 3]\n",
    "print(dm_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3309297-159c-445b-b05b-4789cfeebdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[237.74349354 220.91840438 225.70377197]\n",
      " [238.66634307 221.36258534 226.10543323]\n",
      " [237.00184081 220.4564904  225.24283209]\n",
      " ...\n",
      " [261.51307475 307.52792653 206.95377657]\n",
      " [116.64577116 288.45549013 225.42045149]\n",
      " [ 65.39746066 396.34953017 222.60871912]]\n"
     ]
    }
   ],
   "source": [
    "# Shift positions to have no negatives\n",
    "minimum = min(np.min(dm_pos), np.min(gas_pos))\n",
    "dm_pos = dm_pos - minimum\n",
    "gas_pos = gas_pos - minimum\n",
    "print(dm_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd6c168-69a8-4a08-86da-fd308abfecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[129 120 122]\n",
      " [130 120 123]\n",
      " [129 120 122]\n",
      " ...\n",
      " [142 167 112]\n",
      " [ 63 157 122]\n",
      " [ 35 215 121]]\n"
     ]
    }
   ],
   "source": [
    "# Resize to nvoxel and floor\n",
    "nvoxel = 256\n",
    "maximum = max(np.max(dm_pos), np.max(gas_pos))\n",
    "dm_pos = np.floor(dm_pos * (nvoxel - 1) / maximum).astype(np.int64)\n",
    "gas_pos = np.floor(gas_pos * (nvoxel - 1) / maximum).astype(np.int64)\n",
    "print(dm_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f10ff079-a540-4b70-b80f-b7ba617891f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[129, 130, 129,  ..., 142,  63,  35],\n",
      "                       [120, 120, 120,  ..., 167, 157, 215],\n",
      "                       [122, 123, 122,  ..., 112, 122, 121]]),\n",
      "       values=tensor([0.0472, 0.0472, 0.0472,  ..., 0.0472, 0.0472, 0.0472]),\n",
      "       size=(256, 256, 256), nnz=7886, dtype=torch.float64,\n",
      "       layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "# Then voxelize take the position as indices and the masses as values of a sparse uncoalesced tensor (see https://pytorch.org/docs/stable/sparse.html#sparse-uncoalesced-coo-docs)\n",
    "# Positions are transposed because that's the way torch wants them: columns of indices are the rows of dm_pos.\n",
    "dm_uncoalesced = torch.sparse_coo_tensor(\n",
    "    indices=dm_pos.T, values=dm_mass, size=(nvoxel, nvoxel, nvoxel)\n",
    ")\n",
    "print(dm_uncoalesced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c1d70a8-2b5d-457f-9521-ef00b9d5553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncoalesced:\n",
      " tensor(indices=tensor([[0, 0, 2],\n",
      "                       [1, 1, 2],\n",
      "                       [1, 1, 0]]),\n",
      "       values=tensor([1., 5., 8.]),\n",
      "       size=(4, 4, 4), nnz=3, layout=torch.sparse_coo)\n",
      "coalesced:\n",
      " tensor(indices=tensor([[0, 2],\n",
      "                       [1, 2],\n",
      "                       [1, 0]]),\n",
      "       values=tensor([6., 8.]),\n",
      "       size=(4, 4, 4), nnz=2, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "# Finally, these tensors are coalesced: values with the same index are summed. Check this out\n",
    "uncoalesced = torch.sparse_coo_tensor(\n",
    "    indices=[[0, 0, 2],\n",
    "             [1, 1, 2],\n",
    "             [1, 1, 0]],\n",
    "    values=[1.0, 5.0, 8.0],\n",
    "    size=(4, 4, 4)\n",
    ")\n",
    "coalesced = uncoalesced.coalesce()\n",
    "print(\"uncoalesced:\\n\", uncoalesced)\n",
    "print(\"coalesced:\\n\", coalesced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ed68cb1-d341-482b-b762-c7071f6decf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These tensors are then saved as .npy and than later converted into dense tensors by the dataset.\n",
    "# In this way we avoid saving the intermediate filse about the whole unprocessed halos.\n",
    "# Saving separate files for dark matter and gas give us double the files, but save us a little computation during training.\n",
    "# Storing tensors in sparse format save orders of magnitude in disk space: a tipical dark matter halo has around 1e5 particles (in TNG100-3), but a tensor of shape [256, 256, 256] has 1.67e7 elements\n",
    "# Using .npy format (which is binary) instead of .csv (which is textual) save more or less 50% of disk space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f523919c-72a1-4665-8fc8-81d964aac713",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running the gan with different parameters and architectures a evalute the outcomes on small scale simulations.\n",
    "\n",
    "### Not ready yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722100b-6aeb-4d04-8f6b-877b1e56f6bf",
   "metadata": {},
   "source": [
    "Run the simulations with\n",
    "```\n",
    "python main.py\n",
    "```\n",
    "\n",
    "Options are read from `defaults.py` and overridden by options in an `options.py` file, if present. So copy and rename `defaults.py` without modifying it and change options in `options.py`.\n",
    "\n",
    "If an option is a list, e.g. `generator_depth = [4, 5, 6]`, the program will run multiple times with different parameters, logging the results. Attention: making to many parameters into a list may take long time because the program will run every combination in the cartesian product.\n",
    "\n",
    "Process is logged in `last_run.log` and metrics about the runs are saved in `last_run.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a6b6a7-63f8-4862-85d0-bb0475ba0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "from random import randint, choice\n",
    "import torch\n",
    "from importlib import reload\n",
    "import os\n",
    "import glob\n",
    "from types import SimpleNamespace\n",
    "import logging\n",
    "import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db3f2373-4411-424b-8ce5-1063888d018d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'run_f60d59e38c0aa769a21e60b05bb7c89f/global_metrics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2958/864357902.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_f60d59e38c0aa769a21e60b05bb7c89f/global_metrics.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFacetGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"discriminator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"l1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# g.map(sb.scatterplot, \"epoch\", \"mse\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/baryons-dgAQvMH4/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/baryons-dgAQvMH4/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/baryons-dgAQvMH4/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/baryons-dgAQvMH4/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/baryons-dgAQvMH4/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/baryons-dgAQvMH4/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/baryons-dgAQvMH4/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/baryons-dgAQvMH4/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'run_f60d59e38c0aa769a21e60b05bb7c89f/global_metrics.csv'"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv(\"run_f60d59e38c0aa769a21e60b05bb7c89f/global_metrics.csv\")\n",
    "g = sb.FacetGrid(gm, col=\"discriminator\")\n",
    "g.map(sb.lineplot, \"epoch\", \"l1\")\n",
    "# g.map(sb.scatterplot, \"epoch\", \"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842947df-a2ca-4610-86a1-dfe53fb794ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.default_rng(42).random((20, 3))\n",
    "df = pd.DataFrame(data, columns=[\"time\", \"height\", \"width\"])\n",
    "df[[\"time\", \"width\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c3646-ec9b-4e72-b1ed-3ac976654966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baryons",
   "language": "python",
   "name": "baryons"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
